# ğŸ¬ Streaming de VÃ­deos - Pipeline Completo

## ğŸ“Š VisÃ£o Geral

Este projeto implementa uma soluÃ§Ã£o completa de engenharia de dados, abrangendo desde a ingestÃ£o e transformaÃ§Ã£o de dados atÃ© a criaÃ§Ã£o de dashboards interativos para anÃ¡lise e monitoramento. 

A arquitetura foi desenvolvida utilizando tecnologias modernas de big data, incluindo **Apache Spark**, **Data Lakes** e ferramentas de visualizaÃ§Ã£o avanÃ§adas. A temÃ¡tica escolhida â€” plataforma de streaming de vÃ­deo â€” permite trabalhar com dados realistas e ricos em volume e variedade.

## ğŸ—ï¸ Arquitetura da SoluÃ§Ã£o

O projeto segue uma arquitetura de **Data Lake** com processamento em camadas:

### ğŸ“¥ Camada de IngestÃ£o
- Coleta automatizada de dados de mÃºltiplas fontes
- Processamento em tempo real e batch
- ValidaÃ§Ã£o e qualidade dos dados

### ğŸ¥‰ Bronze Layer
- Dados brutos no formato original
- Armazenamento em formatos Delta/Iceberg
- HistÃ³rico completo de todas as informaÃ§Ãµes

### ğŸ¥ˆ Silver Layer
- Dados limpos e estruturados
- AplicaÃ§Ã£o de regras de negÃ³cio
- PadronizaÃ§Ã£o e normalizaÃ§Ã£o

### ğŸ¥‡ Gold Layer
- Dados agregados e otimizados para consumo
- MÃ©tricas de negÃ³cio calculadas
- Pronto para anÃ¡lises e relatÃ³rios

### ğŸ“ˆ Camada de VisualizaÃ§Ã£o
- Dashboards interativos
- KPIs para tomada de decisÃ£o
- RelatÃ³rios automatizados

## ğŸ¯ Objetivos do Projeto

- **ğŸ“Š AnÃ¡lise de Comportamento**: Entender padrÃµes de consumo de conteÃºdo
- **ğŸ” Monitoramento**: Acompanhar mÃ©tricas de performance em tempo real
- **ğŸ’¡ Insights**: Gerar recomendaÃ§Ãµes baseadas em dados
- **âš¡ Escalabilidade**: Arquitetura preparada para crescimento

## ğŸ› ï¸ Tecnologias Utilizadas

- **ğŸ Python**: Linguagem principal para processamento
- **ğŸŒªï¸ Apache Airflow**: OrquestraÃ§Ã£o de workflows
- **ğŸ³ Docker**: ContainerizaÃ§Ã£o dos serviÃ§os
- **ğŸ—„ï¸ MySQL**: Banco de dados relacional
- **ğŸ“Š Power BI/Grafana**: VisualizaÃ§Ã£o de dados
- **â˜ï¸ Apache Spark**: Processamento distribuÃ­do

## ğŸ“‹ PrÃ©-requisitos

Antes de iniciar, certifique-se de ter instalado em sua mÃ¡quina:

- ğŸ **Python 3.11.9**
- ğŸ³ **Docker Desktop** (manter aberto durante o uso)
- ğŸ“ **Git**
- ğŸ’» **VS Code**
- ğŸš€ **Astro CLI**

## ğŸš€ Como ComeÃ§ar

1. **ğŸ“– Leia a documentaÃ§Ã£o** de configuraÃ§Ã£o do ambiente
2. **âš™ï¸ Configure** seu ambiente de desenvolvimento
3. **ğŸ”„ Execute** os pipelines de dados
4. **ğŸ“Š Explore** os dashboards criados

## ğŸ“ Contexto AcadÃªmico

Este projeto foi desenvolvido como parte do curso de **Engenharia de Dados**, aplicando conceitos modernos de:

- **Data Engineering**: Pipelines robustos e escalÃ¡veis
- **Data Architecture**: PadrÃµes de mercado
- **DevOps**: AutomaÃ§Ã£o e monitoramento
- **Analytics**: Insights orientados por dados

---

ğŸš€ **Pronto para comeÃ§ar?** Acesse a seÃ§Ã£o de [ConfiguraÃ§Ã£o do Ambiente](config-ambiente.md) e siga o passo a passo!